#!/usr/bin/env python3
"""
ë¯¸êµ­ ì£¼ì‹/ETF ì „ì²´ íˆìŠ¤í† ë¦¬ ì¬êµ¬ì¶• (2022-01-01ë¶€í„°)
Yahoo Financeì—ì„œ ë°ì´í„° ê°€ì ¸ì™€ì„œ JSON ìƒì„±
ë³‘ë ¬ ì²˜ë¦¬ë¡œ 5ì‹œê°„ â†’ 1-2ì‹œê°„ìœ¼ë¡œ ë‹¨ì¶•
"""

import os
import json
import time
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock
import yfinance as yf

# ê²½ë¡œ ì„¤ì •
JSON_FILE_PATH = "src/data/momentum/us/us_historical_data.json"
TICKERS_FILE_PATH = "src/data/momentum/us/us_tickers.json"

# ë¡œì»¬ í‹°ì»¤ íŒŒì¼ ê²½ë¡œ (US í´ë” ì „ì²´)
TICKER_FILES = [
    # Stocks
    "src/data/tickers/us/stocks/stocks_us_nasdaq100_with_mcv_id.json",
    "src/data/tickers/us/stocks/stocks_us_s&p500_with_mcv_id.json",
    "src/data/tickers/us/stocks/stocks_us_russell2000_with_mcv_id.json",  # âœ… Russell 2000 ì¶”ê°€
    # ETF
    "src/data/tickers/us/etf/etf_us_largest_with_mcv_id.json",
    "src/data/tickers/us/etf/etf_us_leverage_2x_with_mcv_id.json",
    "src/data/tickers/us/etf/etf_us_leverage_3x_with_mcv_id.json",
    "src/data/tickers/us/etf/etf_us_others_with_mcv_id.json",
    "src/data/tickers/us/etf/etf_us_popular_with_mcv_id.json",
    # Index
    "src/data/tickers/us/index/index_us_with_mcv_id.json",
    # Commodity
    "src/data/tickers/us/commodity/commodity_with_mcv_id.json",
    # Bond
    "src/data/tickers/us/bond/bond_us_with_mcv_id.json",
    # Forex
    "src/data/tickers/us/forex/forex_us_with_mcv_id.json",
]

# âœ… RSI ê³„ì‚° (Wilder ë°©ì‹)
def calculate_rsi(prices, period=14):
    if len(prices) < period + 1:
        return None

    gains = []
    losses = []
    for i in range(1, period + 1):
        change = prices[i] - prices[i - 1]
        gains.append(max(change, 0))
        losses.append(abs(min(change, 0)))

    avg_gain = sum(gains) / period
    avg_loss = sum(losses) / period

    for i in range(period + 1, len(prices)):
        change = prices[i] - prices[i - 1]
        gain = max(change, 0)
        loss = abs(min(change, 0))
        avg_gain = (avg_gain * (period - 1) + gain) / period
        avg_loss = (avg_loss * (period - 1) + loss) / period

    if avg_loss == 0:
        return 100.0
    rs = avg_gain / avg_loss
    return round(100 - (100 / (1 + rs)), 2)

# âœ… EMA ê³„ì‚°
def calculate_ema(prices, period):
    if len(prices) < 1:
        return None
    k = 2 / (period + 1)
    ema = prices[0]
    for price in prices[1:]:
        ema = price * k + ema * (1 - k)
    return round(ema, 8)

# âœ… ë¡œì»¬ í‹°ì»¤ íŒŒì¼ ë¡œë“œ
def load_local_tickers():
    all_tickers = []
    for file_path in TICKER_FILES:
        if not os.path.exists(file_path):
            print(f"âš ï¸ í‹°ì»¤ íŒŒì¼ ì—†ìŒ: {file_path}")
            continue

        with open(file_path, 'r', encoding='utf-8') as f:
            tickers = json.load(f)
            all_tickers.extend(tickers)
            print(f"âœ… ë¡œë“œ: {file_path} - {len(tickers)}ê°œ")

    # ì¤‘ë³µ ì œê±° (mcv_id ê¸°ì¤€)
    unique_tickers = {}
    for t in all_tickers:
        mcv_id = t.get('mcv_id')
        if mcv_id and mcv_id not in unique_tickers:
            unique_tickers[mcv_id] = t

    return list(unique_tickers.values())

# âœ… Yahoo Financeì—ì„œ íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸° (ë³‘ë ¬ ì²˜ë¦¬ìš©)
def fetch_yahoo_history(ticker, start_date, end_date):
    """
    Yahoo Financeì—ì„œ OHLCV ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    ë³‘ë ¬ ì²˜ë¦¬ì‹œ sleep ì œê±° (rate limitì€ ThreadPool í¬ê¸°ë¡œ ì œì–´)
    """
    try:
        # yfinanceê°€ ìë™ìœ¼ë¡œ ì„¸ì…˜ ê´€ë¦¬ (curl_cffi ì‚¬ìš©)
        yf_ticker = yf.Ticker(ticker)
        hist = yf_ticker.history(start=start_date, end=end_date)

        if hist.empty:
            return []

        candles = []
        for date, row in hist.iterrows():
            candles.append({
                'date': date.strftime('%Y-%m-%d'),
                'open': round(float(row['Open']), 2) if row['Open'] else None,
                'high': round(float(row['High']), 2) if row['High'] else None,
                'low': round(float(row['Low']), 2) if row['Low'] else None,
                'close': round(float(row['Close']), 2) if row['Close'] else None,
                'volume': int(row['Volume']) if row['Volume'] else 0,
                'rsi': None,
                'ema200_diff': None,
                'ema120_diff': None,
                'ema50_diff': None,
                'ema20_diff': None,
                'volume_ratio_90d': None,
                'volume_ratio_alltime': None
            })

        return candles

    except Exception as e:
        return []  # ì¡°ìš©íˆ ì‹¤íŒ¨ (ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ ë¡œê¹…)

# âœ… ë‹¨ì¼ í‹°ì»¤ ì²˜ë¦¬ í•¨ìˆ˜ (ë³‘ë ¬í™”ìš©)
def process_single_ticker(t, start_date, end_date, index, total):
    """ë‹¨ì¼ í‹°ì»¤ ì²˜ë¦¬ (ë³‘ë ¬ ì‹¤í–‰)"""
    ticker = t.get('ticker')
    mcv_id = t.get('mcv_id')
    ko_name = t.get('ko_name')

    if not ticker or not mcv_id:
        return None, f"âš ï¸ [{index}/{total}] ì˜ëª»ëœ í‹°ì»¤ ë°ì´í„°"

    try:
        # Yahoo Financeì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        candles = fetch_yahoo_history(ticker, start_date, end_date)

        if len(candles) == 0:
            return None, f"âŒ [{index}/{total}] {ticker} ë°ì´í„° ì—†ìŒ"

        # íˆìŠ¤í† ë¦¬ êµ¬ì¶•
        history = candles

        # ìµœê·¼ 250ì¼ ë°ì´í„°ë¡œ ì§€í‘œ ê³„ì‚°
        recent_history = history[-250:]
        closes = [h['close'] for h in recent_history if h['close'] is not None]
        volumes = [h['volume'] for h in recent_history if h['volume'] is not None]

        if len(closes) < 14:
            return None, f"âš ï¸ [{index}/{total}] {ticker} ë°ì´í„° ë¶€ì¡±"

        # RSI ê³„ì‚°
        rsi = calculate_rsi(closes)

        # EMA ê³„ì‚°
        ema20 = calculate_ema(closes, 20) if len(closes) >= 20 else None
        ema50 = calculate_ema(closes, 50) if len(closes) >= 50 else None
        ema120 = calculate_ema(closes, 120) if len(closes) >= 120 else None
        ema200 = calculate_ema(closes, 200) if len(closes) >= 200 else None

        current_price = closes[-1]
        ema20_diff = round(((current_price - ema20) / ema20) * 100, 2) if ema20 else None
        ema50_diff = round(((current_price - ema50) / ema50) * 100, 2) if ema50 else None
        ema120_diff = round(((current_price - ema120) / ema120) * 100, 2) if ema120 else None
        ema200_diff = round(((current_price - ema200) / ema200) * 100, 2) if ema200 else None

        # ê±°ë˜ëŸ‰ ë¹„ìœ¨
        if len(volumes) > 0:
            vol_max_90d = max(volumes[-90:]) if len(volumes) >= 90 else max(volumes)
            vol_ratio_90d = round(volumes[-1] / vol_max_90d, 3) if vol_max_90d else None
            vol_max_alltime = max(volumes)
            vol_ratio_alltime = round(volumes[-1] / vol_max_alltime, 3) if vol_max_alltime else None
        else:
            vol_ratio_90d = None
            vol_ratio_alltime = None

        # ìµœì‹  ë ˆì½”ë“œì— ì§€í‘œ ì—…ë°ì´íŠ¸
        history[-1]['rsi'] = rsi
        history[-1]['ema20_diff'] = ema20_diff
        history[-1]['ema50_diff'] = ema50_diff
        history[-1]['ema120_diff'] = ema120_diff
        history[-1]['ema200_diff'] = ema200_diff
        history[-1]['volume_ratio_90d'] = vol_ratio_90d
        history[-1]['volume_ratio_alltime'] = vol_ratio_alltime

        return {
            'ticker_data': {
                'mcv_id': mcv_id,
                'ticker': ticker,
                'ko_name': ko_name,
                'history': history
            },
            'ticker_info': {
                'mcv_id': mcv_id,
                'ticker': ticker,
                'ko_name': ko_name
            }
        }, f"âœ… [{index}/{total}] {ticker} {len(candles)}ê°œ"

    except Exception as e:
        return None, f"âŒ [{index}/{total}] {ticker} ì—ëŸ¬: {e}"

# âœ… í‹°ì»¤ ëª©ë¡ ì €ì¥
def save_tickers(tickers):
    os.makedirs(os.path.dirname(TICKERS_FILE_PATH), exist_ok=True)
    with open(TICKERS_FILE_PATH, 'w', encoding='utf-8') as f:
        json.dump({
            'generated_at': datetime.now().isoformat(),
            'tickers': tickers
        }, f, ensure_ascii=False, indent=2)

# âœ… JSON íŒŒì¼ ì €ì¥
def save_json_data(data):
    os.makedirs(os.path.dirname(JSON_FILE_PATH), exist_ok=True)
    with open(JSON_FILE_PATH, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

# âœ… ë©”ì¸ ì‹¤í–‰ (ë³‘ë ¬ ì²˜ë¦¬)
def main():
    print("ğŸš€ ë¯¸êµ­ ì£¼ì‹/ETF ì „ì²´ íˆìŠ¤í† ë¦¬ ì¬êµ¬ì¶• ì‹œì‘ (ë³‘ë ¬ ì²˜ë¦¬)")

    start_date = "2022-01-01"
    end_date = datetime.now().strftime("%Y-%m-%d")

    print(f"ğŸ“… ìˆ˜ì§‘ ê¸°ê°„: {start_date} ~ {end_date}")

    # 1. ë¡œì»¬ í‹°ì»¤ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
    tickers = load_local_tickers()
    print(f"ğŸ“‹ ì´ {len(tickers)}ê°œ í‹°ì»¤ ì²˜ë¦¬ ì¤‘...\n")
    print(f"âš¡ ë³‘ë ¬ ì²˜ë¦¬: 20ê°œ ìŠ¤ë ˆë“œ (ì˜ˆìƒ ì‹œê°„: 1-2ì‹œê°„)\n")

    all_data = []
    all_tickers = []
    failed = 0
    print_lock = Lock()

    # ë³‘ë ¬ ì²˜ë¦¬ (20ê°œ ìŠ¤ë ˆë“œ)
    with ThreadPoolExecutor(max_workers=20) as executor:
        # ëª¨ë“  ì‘ì—…ì„ ì œì¶œ
        future_to_ticker = {
            executor.submit(process_single_ticker, t, start_date, end_date, i+1, len(tickers)): t
            for i, t in enumerate(tickers)
        }

        # ì™„ë£Œëœ ì‘ì—… ì²˜ë¦¬
        for future in as_completed(future_to_ticker):
            result, log_msg = future.result()

            with print_lock:
                print(log_msg)

                if result:
                    all_data.append(result['ticker_data'])
                    all_tickers.append(result['ticker_info'])
                else:
                    failed += 1

                # ì§„í–‰ ìƒí™© (50ê°œë§ˆë‹¤)
                if len(all_data) % 50 == 0:
                    print(f"   ğŸ“Š ì§„í–‰: {len(all_data) + failed}/{len(tickers)} ({(len(all_data) + failed)*100//len(tickers)}%)")

    # JSON ì €ì¥
    json_data = {
        'generated_at': datetime.now().isoformat(),
        'cutoff_date': start_date,
        'total_tickers': len(all_data),
        'total_records': sum(len(t['history']) for t in all_data),
        'data': all_data
    }

    save_json_data(json_data)
    save_tickers(all_tickers)

    print(f"\nâœ… ì¬êµ¬ì¶• ì™„ë£Œ!")
    print(f"   - ì„±ê³µ: {len(all_data)}ê°œ")
    print(f"   - ì‹¤íŒ¨: {failed}ê°œ")
    print(f"   - ì´ ë ˆì½”ë“œ: {json_data['total_records']}")
    print(f"   - ì‹œì‘ì¼: {start_date}")
    print(f"   - ì¢…ë£Œì¼: {end_date}")

    if os.path.exists(JSON_FILE_PATH):
        file_size = os.path.getsize(JSON_FILE_PATH) / 1024 / 1024
        print(f"   - íŒŒì¼ í¬ê¸°: {file_size:.2f} MB")

if __name__ == "__main__":
    main()
