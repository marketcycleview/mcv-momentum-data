#!/usr/bin/env python3
"""
ë¯¸êµ­ ì£¼ì‹/ETF ì¼ì¼ ì—…ë°ì´íŠ¸ (ì¦ë¶„ ì—…ë°ì´íŠ¸)
- ê¸°ì¡´ í‹°ì»¤: ì–´ì œ ë°ì´í„°ë§Œ ì¶”ê°€
- ì‹ ê·œ í‹°ì»¤: 2022-01-01ë¶€í„° ì „ì²´ íˆìŠ¤í† ë¦¬ ë‹¤ìš´ë¡œë“œ
"""

import os
import json
import time
from datetime import datetime, timedelta
import yfinance as yf

# ê²½ë¡œ ì„¤ì •
JSON_FILE_PATH = "src/data/momentum/us/us_historical_data.json"
TICKERS_FILE_PATH = "src/data/momentum/us/us_tickers.json"

# ë¡œì»¬ í‹°ì»¤ íŒŒì¼ ê²½ë¡œ (US í´ë” ì „ì²´)
TICKER_FILES = [
    # Stocks
    "src/data/tickers/us/stocks/stocks_us_nasdaq100_with_mcv_id.json",
    "src/data/tickers/us/stocks/stocks_us_s&p500_with_mcv_id.json",
    "src/data/tickers/us/stocks/stocks_us_russell2000_with_mcv_id.json",  # âœ… Russell 2000 ì¶”ê°€
    # ETF
    "src/data/tickers/us/etf/etf_us_largest_with_mcv_id.json",
    "src/data/tickers/us/etf/etf_us_leverage_2x_with_mcv_id.json",
    "src/data/tickers/us/etf/etf_us_leverage_3x_with_mcv_id.json",
    "src/data/tickers/us/etf/etf_us_others_with_mcv_id.json",
    "src/data/tickers/us/etf/etf_us_popular_with_mcv_id.json",
    # Index
    "src/data/tickers/us/index/index_us_with_mcv_id.json",
    # Commodity
    "src/data/tickers/us/commodity/commodity_with_mcv_id.json",
    # Bond
    "src/data/tickers/us/bond/bond_us_with_mcv_id.json",
    # Forex
    "src/data/tickers/us/forex/forex_us_with_mcv_id.json",
]

# ì‹ ê·œ í‹°ì»¤ ìµœëŒ€ ì²˜ë¦¬ ê°œìˆ˜ (rate limit ê³ ë ¤)
MAX_NEW_TICKERS = 5

# âœ… RSI ê³„ì‚° (Wilder ë°©ì‹)
def calculate_rsi(prices, period=14):
    if len(prices) < period + 1:
        return None

    gains = []
    losses = []
    for i in range(1, period + 1):
        change = prices[i] - prices[i - 1]
        gains.append(max(change, 0))
        losses.append(abs(min(change, 0)))

    avg_gain = sum(gains) / period
    avg_loss = sum(losses) / period

    for i in range(period + 1, len(prices)):
        change = prices[i] - prices[i - 1]
        gain = max(change, 0)
        loss = abs(min(change, 0))
        avg_gain = (avg_gain * (period - 1) + gain) / period
        avg_loss = (avg_loss * (period - 1) + loss) / period

    if avg_loss == 0:
        return 100.0
    rs = avg_gain / avg_loss
    return round(100 - (100 / (1 + rs)), 2)

# âœ… EMA ê³„ì‚°
def calculate_ema(prices, period):
    if len(prices) < 1:
        return None
    k = 2 / (period + 1)
    ema = prices[0]
    for price in prices[1:]:
        ema = price * k + ema * (1 - k)
    return round(ema, 8)

# âœ… ë¡œì»¬ í‹°ì»¤ íŒŒì¼ ë¡œë“œ
def load_local_tickers():
    all_tickers = []
    for file_path in TICKER_FILES:
        if not os.path.exists(file_path):
            print(f"âš ï¸ í‹°ì»¤ íŒŒì¼ ì—†ìŒ: {file_path}")
            continue

        with open(file_path, 'r', encoding='utf-8') as f:
            tickers = json.load(f)
            all_tickers.extend(tickers)

    # ì¤‘ë³µ ì œê±° (mcv_id ê¸°ì¤€)
    unique_tickers = {}
    for t in all_tickers:
        mcv_id = t.get('mcv_id')
        if mcv_id and mcv_id not in unique_tickers:
            unique_tickers[mcv_id] = t

    return list(unique_tickers.values())

# âœ… ê¸°ì¡´ JSON ë°ì´í„° ë¡œë“œ
def load_existing_data():
    if not os.path.exists(JSON_FILE_PATH):
        print("âš ï¸ ê¸°ì¡´ JSON íŒŒì¼ ì—†ìŒ - ì¬êµ¬ì¶• ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”")
        return None

    with open(JSON_FILE_PATH, 'r', encoding='utf-8') as f:
        return json.load(f)

# âœ… Yahoo Financeì—ì„œ ìµœê·¼ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
def fetch_yahoo_recent(ticker, start_date, end_date):
    """ë‹¨ì¼ ë‚ ì§œ ë˜ëŠ” ìµœê·¼ ë©°ì¹  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    try:
        yf_ticker = yf.Ticker(ticker)
        hist = yf_ticker.history(start=start_date, end=end_date)

        if hist.empty:
            return []

        candles = []
        for date, row in hist.iterrows():
            candles.append({
                'date': date.strftime('%Y-%m-%d'),
                'open': round(float(row['Open']), 2) if row['Open'] else None,
                'high': round(float(row['High']), 2) if row['High'] else None,
                'low': round(float(row['Low']), 2) if row['Low'] else None,
                'close': round(float(row['Close']), 2) if row['Close'] else None,
                'volume': int(row['Volume']) if row['Volume'] else 0,
                'rsi': None,
                'ema200_diff': None,
                'ema120_diff': None,
                'ema50_diff': None,
                'ema20_diff': None,
                'volume_ratio_90d': None,
                'volume_ratio_alltime': None
            })

        return candles

    except Exception as e:
        print(f"âŒ {ticker} ì—ëŸ¬: {e}")
        return []

# âœ… ì „ì²´ íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸° (ì‹ ê·œ í‹°ì»¤ìš©)
def fetch_yahoo_full_history(ticker, start_date="2022-01-01"):
    """2022-01-01ë¶€í„° ì „ì²´ íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸°"""
    end_date = datetime.now().strftime("%Y-%m-%d")
    return fetch_yahoo_recent(ticker, start_date, end_date)

# âœ… ì§€í‘œ ê³„ì‚° ë° ì—…ë°ì´íŠ¸
def calculate_and_update_indicators(history):
    """ìµœì‹  ë ˆì½”ë“œì— RSI, EMA, ê±°ë˜ëŸ‰ë¹„ìœ¨ ê³„ì‚°"""
    if len(history) == 0:
        return

    recent_history = history[-250:]
    closes = [h['close'] for h in recent_history if h['close'] is not None]
    volumes = [h['volume'] for h in recent_history if h['volume'] is not None]

    if len(closes) < 14:
        return

    # RSI ê³„ì‚°
    rsi = calculate_rsi(closes)

    # EMA ê³„ì‚°
    ema20 = calculate_ema(closes, 20) if len(closes) >= 20 else None
    ema50 = calculate_ema(closes, 50) if len(closes) >= 50 else None
    ema120 = calculate_ema(closes, 120) if len(closes) >= 120 else None
    ema200 = calculate_ema(closes, 200) if len(closes) >= 200 else None

    current_price = closes[-1]
    ema20_diff = round(((current_price - ema20) / ema20) * 100, 2) if ema20 else None
    ema50_diff = round(((current_price - ema50) / ema50) * 100, 2) if ema50 else None
    ema120_diff = round(((current_price - ema120) / ema120) * 100, 2) if ema120 else None
    ema200_diff = round(((current_price - ema200) / ema200) * 100, 2) if ema200 else None

    # ê±°ë˜ëŸ‰ ë¹„ìœ¨
    if len(volumes) > 0:
        vol_max_90d = max(volumes[-90:]) if len(volumes) >= 90 else max(volumes)
        vol_ratio_90d = round(volumes[-1] / vol_max_90d, 3) if vol_max_90d else None
        vol_max_alltime = max(volumes)
        vol_ratio_alltime = round(volumes[-1] / vol_max_alltime, 3) if vol_max_alltime else None
    else:
        vol_ratio_90d = None
        vol_ratio_alltime = None

    # ìµœì‹  ë ˆì½”ë“œ ì—…ë°ì´íŠ¸
    history[-1]['rsi'] = rsi
    history[-1]['ema20_diff'] = ema20_diff
    history[-1]['ema50_diff'] = ema50_diff
    history[-1]['ema120_diff'] = ema120_diff
    history[-1]['ema200_diff'] = ema200_diff
    history[-1]['volume_ratio_90d'] = vol_ratio_90d
    history[-1]['volume_ratio_alltime'] = vol_ratio_alltime

# âœ… JSON íŒŒì¼ ì €ì¥
def save_json_data(data):
    os.makedirs(os.path.dirname(JSON_FILE_PATH), exist_ok=True)
    with open(JSON_FILE_PATH, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

# âœ… ë©”ì¸ ì‹¤í–‰
def main():
    print("ğŸ”„ ë¯¸êµ­ ì£¼ì‹/ETF ì¼ì¼ ì—…ë°ì´íŠ¸ ì‹œì‘...")

    # ì–´ì œ ë‚ ì§œ ê³„ì‚° (ë¯¸êµ­ ì‹œì¥ ê¸°ì¤€)
    yesterday = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")
    print(f"ğŸ“… ì—…ë°ì´íŠ¸ ë‚ ì§œ: {yesterday}\n")

    # 1. í‹°ì»¤ ì†ŒìŠ¤ ë¡œë“œ
    local_tickers = load_local_tickers()
    print(f"ğŸ“‹ ë¡œì»¬ í‹°ì»¤: {len(local_tickers)}ê°œ")

    # TODO: Watchlist í‹°ì»¤ ê°€ì ¸ì˜¤ê¸° (DB ì—°ë™)
    # watchlist_tickers = get_watchlist_tickers()
    # all_tickers = merge_unique(local_tickers, watchlist_tickers)
    all_tickers = local_tickers  # í˜„ì¬ëŠ” ë¡œì»¬ë§Œ

    # 2. ê¸°ì¡´ JSON ë°ì´í„° ë¡œë“œ
    existing_data = load_existing_data()
    if not existing_data:
        print("âŒ ê¸°ì¡´ ë°ì´í„° ì—†ìŒ - rebuild_us_history.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”")
        return

    # ê¸°ì¡´ í‹°ì»¤ ë§µ ìƒì„±
    existing_map = {item['mcv_id']: item for item in existing_data['data']}
    existing_mcv_ids = set(existing_map.keys())

    # 3. ì‹ ê·œ í‹°ì»¤ vs ê¸°ì¡´ í‹°ì»¤ ë¶„ë¦¬
    new_tickers = [t for t in all_tickers if t['mcv_id'] not in existing_mcv_ids]
    existing_tickers = [t for t in all_tickers if t['mcv_id'] in existing_mcv_ids]

    print(f"ğŸ†• ì‹ ê·œ í‹°ì»¤: {len(new_tickers)}ê°œ")
    print(f"ğŸ”„ ê¸°ì¡´ í‹°ì»¤: {len(existing_tickers)}ê°œ\n")

    # 4. ê¸°ì¡´ í‹°ì»¤ ì—…ë°ì´íŠ¸ (ì–´ì œ ë°ì´í„°ë§Œ ì¶”ê°€)
    updated_count = 0
    print("ğŸ“Š ê¸°ì¡´ í‹°ì»¤ ì—…ë°ì´íŠ¸ ì¤‘...")
    for t in existing_tickers:
        ticker = t['ticker']
        mcv_id = t['mcv_id']

        try:
            # ì–´ì œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            candles = fetch_yahoo_recent(ticker, yesterday, yesterday)

            if len(candles) == 0:
                continue  # ì£¼ë§/íœ´ì¼ì´ë©´ ìŠ¤í‚µ

            # ê¸°ì¡´ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            ticker_data = existing_map[mcv_id]

            # ì¤‘ë³µ ì²´í¬ (ì´ë¯¸ ì–´ì œ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë®ì–´ì“°ê¸°)
            existing_dates = {h['date'] for h in ticker_data['history']}
            for candle in candles:
                if candle['date'] not in existing_dates:
                    ticker_data['history'].append(candle)

            # ì§€í‘œ ì¬ê³„ì‚°
            calculate_and_update_indicators(ticker_data['history'])
            updated_count += 1

            if updated_count % 50 == 0:
                print(f"   ì§„í–‰: {updated_count}/{len(existing_tickers)}")

        except Exception as e:
            print(f"âŒ {ticker} ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            continue

        time.sleep(0.05)  # Rate limit

    print(f"âœ… ê¸°ì¡´ í‹°ì»¤ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {updated_count}ê°œ\n")

    # 5. ì‹ ê·œ í‹°ì»¤ ì²˜ë¦¬ (ì „ì²´ íˆìŠ¤í† ë¦¬ ë‹¤ìš´ë¡œë“œ)
    if len(new_tickers) > 0:
        print(f"ğŸ†• ì‹ ê·œ í‹°ì»¤ ì²˜ë¦¬ ì¤‘...")

        # ìµœëŒ€ 5ê°œê¹Œì§€ë§Œ ì²˜ë¦¬ (ë‚˜ë¨¸ì§€ëŠ” ë‹¤ìŒë‚ )
        if len(new_tickers) > MAX_NEW_TICKERS:
            print(f"âš ï¸ ì‹ ê·œ í‹°ì»¤ {len(new_tickers)}ê°œ ê°ì§€ - ì˜¤ëŠ˜ì€ {MAX_NEW_TICKERS}ê°œë§Œ ì²˜ë¦¬")
            process_new = new_tickers[:MAX_NEW_TICKERS]
        else:
            process_new = new_tickers

        for t in process_new:
            ticker = t['ticker']
            mcv_id = t['mcv_id']
            ko_name = t.get('ko_name')

            print(f"   ğŸ†• {ticker} - 2022-01-01ë¶€í„° ë‹¤ìš´ë¡œë“œ ì¤‘...", end=" ", flush=True)

            try:
                # ì „ì²´ íˆìŠ¤í† ë¦¬ ë‹¤ìš´ë¡œë“œ
                candles = fetch_yahoo_full_history(ticker)

                if len(candles) == 0:
                    print("âŒ ë°ì´í„° ì—†ìŒ")
                    continue

                print(f"âœ… {len(candles)}ê°œ")

                # ì§€í‘œ ê³„ì‚°
                calculate_and_update_indicators(candles)

                # ë°ì´í„°ì— ì¶”ê°€
                existing_data['data'].append({
                    'mcv_id': mcv_id,
                    'ticker': ticker,
                    'ko_name': ko_name,
                    'history': candles
                })

                time.sleep(0.1)  # Rate limit

            except Exception as e:
                print(f"âŒ {ticker} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
                continue

        print(f"âœ… ì‹ ê·œ í‹°ì»¤ ì²˜ë¦¬ ì™„ë£Œ: {len(process_new)}ê°œ\n")

    # 6. ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
    existing_data['generated_at'] = datetime.now().isoformat()
    existing_data['total_tickers'] = len(existing_data['data'])
    existing_data['total_records'] = sum(len(t['history']) for t in existing_data['data'])

    # 7. JSON ì €ì¥
    save_json_data(existing_data)

    print("âœ… ì¼ì¼ ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
    print(f"   - ì´ í‹°ì»¤: {existing_data['total_tickers']}ê°œ")
    print(f"   - ì´ ë ˆì½”ë“œ: {existing_data['total_records']}")
    print(f"   - ì—…ë°ì´íŠ¸ ì‹œê°: {existing_data['generated_at']}")

    if os.path.exists(JSON_FILE_PATH):
        file_size = os.path.getsize(JSON_FILE_PATH) / 1024 / 1024
        print(f"   - íŒŒì¼ í¬ê¸°: {file_size:.2f} MB")

if __name__ == "__main__":
    main()
